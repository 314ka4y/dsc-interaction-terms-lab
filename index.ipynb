{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interactions - Lab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this lab, you'll explore interactions in the Ames Housing dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objectives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will be able to:\n",
    "- Implement interaction terms in Python using the `sklearn` and `statsmodels` packages \n",
    "- Interpret interaction variables in the context of a real-world problem "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build a baseline model "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You'll use a couple of built-in functions, which we imported for you below: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# __SOLUTION__ \n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you still want to build a model in the end, you can do that, but this lab will just focus on finding meaningful insights in interactions and how they can improve $R^2$ values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regression = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# __SOLUTION__ \n",
    "regression = LinearRegression()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a baseline model which includes all the variables we selected from the Ames housing data set to predict the house prices. Then use 10-fold cross-validation and report the mean $R^2$ value as the baseline $R^2$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ames = pd.read_csv('ames.csv')\n",
    "\n",
    "continuous = ['LotArea', '1stFlrSF', 'GrLivArea', 'SalePrice']\n",
    "categoricals = ['BldgType', 'KitchenQual', 'SaleType', 'MSZoning', 'Street', 'Neighborhood']\n",
    "\n",
    "## code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# __SOLUTION__ \n",
    "ames = pd.read_csv('ames.csv')\n",
    "\n",
    "continuous = ['LotArea', '1stFlrSF', 'GrLivArea', 'SalePrice']\n",
    "categoricals = ['BldgType', 'KitchenQual', 'SaleType', 'MSZoning', 'Street', 'Neighborhood']\n",
    "\n",
    "ames_cont = ames[continuous]\n",
    "\n",
    "# log features\n",
    "log_names = [f'{column}_log' for column in ames_cont.columns]\n",
    "\n",
    "ames_log = np.log(ames_cont)\n",
    "ames_log.columns = log_names\n",
    "\n",
    "# normalize (subract mean and divide by std)\n",
    "\n",
    "def normalize(feature):\n",
    "    return (feature - feature.mean()) / feature.std()\n",
    "\n",
    "ames_log_norm = ames_log.apply(normalize)\n",
    "\n",
    "# one hot encode categoricals\n",
    "ames_ohe = pd.get_dummies(ames[categoricals], prefix=categoricals)\n",
    "\n",
    "preprocessed = pd.concat([ames_cont, ames_ohe], axis=1)\n",
    "\n",
    "X = preprocessed.drop('SalePrice', axis=1)\n",
    "y = preprocessed['SalePrice']\n",
    "\n",
    "crossvalidation = KFold(n_splits=10, shuffle=True, random_state=1)\n",
    "baseline = np.mean(cross_val_score(regression, X, y, scoring='r2', cv=crossvalidation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# __SOLUTION__ \n",
    "baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## See how interactions improve your baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, create all possible combinations of interactions, loop over them and add them to the baseline model one by one to see how they affect the $R^2$. We'll look at the 3 interactions which have the biggest effect on our $R^2$, so print out the top 3 combinations.\n",
    "\n",
    "You will create a `for` loop to loop through all the combinations of 2 predictors. You can use `combinations` from itertools to create a list of all the pairwise combinations. To find more info on how this is done, have a look [here](https://docs.python.org/2/library/itertools.html).\n",
    "\n",
    "Since there are so many different neighbourhoods we will exclude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## code to find top interactions by R^2 value here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# __SOLUTION__ \n",
    "from itertools import combinations\n",
    "\n",
    "interactions = []\n",
    "\n",
    "feat_combinations = combinations(X.columns, 2)\n",
    "\n",
    "data = X.copy()\n",
    "for i, (a, b) in enumerate(feat_combinations):\n",
    "    data['interaction'] = data[a] * data[b]\n",
    "    score = np.mean(cross_val_score(regression, data, y, scoring='r2', cv=crossvalidation))\n",
    "    if score > baseline:\n",
    "        interactions.append((a, b, round(score,3)))\n",
    "    \n",
    "    if i % 50 == 0:\n",
    "        print(i)\n",
    "            \n",
    "print('Top 3 interactions: %s' %sorted(interactions, key=lambda inter: inter[2], reverse=True)[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like the top interactions involve the Neighborhood_Edwards feature so lets add the interaction between LotArea and Edwards to our model.\n",
    "\n",
    "We can interpret this feature as the relationship between LotArea and SalePrice when the house is in Edwards or not."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize the Interaction\n",
    "\n",
    "Separate all houses that are located in Edwards and those that are not. Run a linear regression on each population against `SalePrice`. Visualize the regression line and data points with price on the y axis and LotArea on the x axis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# __SOLUTION__\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(13, 10))\n",
    "\n",
    "col = 'LotArea'\n",
    "\n",
    "is_in = preprocessed.loc[preprocessed['Neighborhood_Edwards'] == 1, [col, 'SalePrice']]\n",
    "\n",
    "linreg = LinearRegression()\n",
    "linreg.fit(np.log(is_in[[col]]), np.log(is_in['SalePrice']))\n",
    "\n",
    "preds = linreg.predict(np.log(is_in[[col]]))\n",
    "\n",
    "ax.scatter(np.log(is_in[[col]]), np.log(is_in['SalePrice']), alpha=.3, label=None)\n",
    "\n",
    "x = np.linspace(6, 12)\n",
    "ax.plot(x, linreg.predict(x.reshape(-1, 1)), label=f'In Edwards:   {linreg.coef_[0]:.2f}')\n",
    "\n",
    "not_in = preprocessed.loc[preprocessed['Neighborhood_Edwards'] == 0, [col, 'SalePrice']]\n",
    "\n",
    "linreg = LinearRegression()\n",
    "linreg.fit(np.log(not_in[[col]]), np.log(not_in['SalePrice']))\n",
    "\n",
    "preds = linreg.predict(np.log(not_in[[col]]))\n",
    "\n",
    "ax.scatter(np.log(not_in[[col]]), np.log(not_in['SalePrice']), alpha=.1, label=None)\n",
    "\n",
    "x = np.linspace(6, 12)\n",
    "ax.plot(x, linreg.predict(x.reshape(-1, 1)), label=f'Outside of Edwards:   {linreg.coef_[0]:.2f}')\n",
    "\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build a final model with interactions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use 10-fold cross-validation to build a model using the above interaction. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# __SOLUTION__ \n",
    "regression = LinearRegression()\n",
    "crossvalidation = KFold(n_splits=10, shuffle=True, random_state=1)\n",
    "final = X.copy()\n",
    "\n",
    "final['Neighborhood_Edwards*LotArea'] = final['Neighborhood_Edwards'] * final['LotArea']\n",
    "\n",
    "final_model = np.mean(cross_val_score(regression, final, y, scoring='r2', cv=crossvalidation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# __SOLUTION__ \n",
    "final_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our $R^2$ has increased considerably! Let's have a look in `statsmodels` to see if this interactions are significant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# __SOLUTION__ \n",
    "import statsmodels.api as sm\n",
    "df_inter_sm = sm.add_constant(final)\n",
    "model = sm.OLS(y,final)\n",
    "results = model.fit()\n",
    "\n",
    "results.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is your conclusion here?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# formulate your conclusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# __SOLUTION__ \n",
    "\"\"\"   \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should now understand how to include interaction effects in your model! As you can see, interactions can have a strong impact on linear regression models, and they should always be considered when you are constructing your models."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
